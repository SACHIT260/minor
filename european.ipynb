{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "999120b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7302b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b50cf484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d23376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4997df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c36198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f185f02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>-1.593105</td>\n",
       "      <td>2.711941</td>\n",
       "      <td>-0.689256</td>\n",
       "      <td>4.626942</td>\n",
       "      <td>-0.924459</td>\n",
       "      <td>1.107641</td>\n",
       "      <td>1.991691</td>\n",
       "      <td>0.510632</td>\n",
       "      <td>-0.682920</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>-0.150189</td>\n",
       "      <td>0.915802</td>\n",
       "      <td>1.214756</td>\n",
       "      <td>-0.675143</td>\n",
       "      <td>1.164931</td>\n",
       "      <td>-0.711757</td>\n",
       "      <td>-0.025693</td>\n",
       "      <td>-1.221179</td>\n",
       "      <td>-1.545556</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>0.411614</td>\n",
       "      <td>0.063119</td>\n",
       "      <td>-0.183699</td>\n",
       "      <td>-0.510602</td>\n",
       "      <td>1.329284</td>\n",
       "      <td>0.140716</td>\n",
       "      <td>0.313502</td>\n",
       "      <td>0.395652</td>\n",
       "      <td>-0.577252</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>-1.933849</td>\n",
       "      <td>-0.962886</td>\n",
       "      <td>-1.042082</td>\n",
       "      <td>0.449624</td>\n",
       "      <td>1.962563</td>\n",
       "      <td>-0.608577</td>\n",
       "      <td>0.509928</td>\n",
       "      <td>1.113981</td>\n",
       "      <td>2.897849</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>-1.040458</td>\n",
       "      <td>-0.031513</td>\n",
       "      <td>-0.188093</td>\n",
       "      <td>-0.084316</td>\n",
       "      <td>0.041333</td>\n",
       "      <td>-0.302620</td>\n",
       "      <td>-0.660377</td>\n",
       "      <td>0.167430</td>\n",
       "      <td>-0.256117</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9       V10       V11       V12  \\\n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  4.356170 -1.593105  2.711941   \n",
       "284803  1.058415  0.024330  0.294869  0.584800 -0.975926 -0.150189  0.915802   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454 -0.484782  0.411614  0.063119   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087 -0.399126 -1.933849 -0.962886   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180 -0.915427 -1.040458 -0.031513   \n",
       "\n",
       "             V13       V14       V15       V16       V17       V18       V19  \\\n",
       "284802 -0.689256  4.626942 -0.924459  1.107641  1.991691  0.510632 -0.682920   \n",
       "284803  1.214756 -0.675143  1.164931 -0.711757 -0.025693 -1.221179 -1.545556   \n",
       "284804 -0.183699 -0.510602  1.329284  0.140716  0.313502  0.395652 -0.577252   \n",
       "284805 -1.042082  0.449624  1.962563 -0.608577  0.509928  1.113981  2.897849   \n",
       "284806 -0.188093 -0.084316  0.041333 -0.302620 -0.660377  0.167430 -0.256117   \n",
       "\n",
       "             V20       V21       V22       V23       V24       V25       V26  \\\n",
       "284802  1.475829  0.213454  0.111864  1.014480 -0.509348  1.436807  0.250034   \n",
       "284803  0.059616  0.214205  0.924384  0.012463 -1.016226 -0.606624 -0.395255   \n",
       "284804  0.001396  0.232045  0.578229 -0.037501  0.640134  0.265745 -0.087371   \n",
       "284805  0.127434  0.265245  0.800049 -0.163298  0.123205 -0.569159  0.546668   \n",
       "284806  0.382948  0.261057  0.643078  0.376777  0.008797 -0.473649 -0.818267   \n",
       "\n",
       "             V27       V28  Amount  Class  \n",
       "284802  0.943651  0.823731    0.77      0  \n",
       "284803  0.068472 -0.053527   24.79      0  \n",
       "284804  0.004455 -0.026561   67.88      0  \n",
       "284805  0.108821  0.104533   10.00      0  \n",
       "284806 -0.002415  0.013649  217.00      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3795ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87e022b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows 284807\n",
      "Number of Columns 31\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Rows\",data.shape[0])\n",
    "print(\"Number of Columns\",data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8518f576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08960052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e1b6afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e1ca7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "data['Amount']=sc.fit_transform(pd.DataFrame(data['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e005b136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8781c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e6009fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59ae3ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69fcbd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "202474f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe6941d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73d9006e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    275190\n",
       "1       473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2748db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b4b08b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebb8996b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Class'].value_counts().plot(kind='bar', color=['blue', 'orange'])\n",
    "plt.title('Count of Fraud vs Non-Fraud')\n",
    "plt.xlabel('Fraud Status')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd40851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class',axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "788ba68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab5fc9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = data[data['Class']==0]\n",
    "fraud = data[data['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2e6ccf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275190, 30)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "569b0fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a72e0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (replace this with your dataset)\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "# Drop irrelevant columns (if any)\n",
    "X = df.drop('Class', axis=1)  # Features (replace 'Class' with the fraud column in your dataset)\n",
    "y = df['Class']  # Target (0 = Legitimate, 1 = Fraud)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42fe5bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to the training data\n",
    "sm = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f994093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    199008\n",
       "1    199008\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_resampled).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaf1f205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance after applying SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.39      0.82      0.53       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.70      0.91      0.76     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "[[85135   172]\n",
      " [   25   111]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Decision Tree model\n",
    "model = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(\"Performance after applying SMOTE:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56e3b1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9976943693456456"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ecb0e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.392226148409894"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "precision_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fcdcdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8161764705882353"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7981041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5298329355608592"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "696e524d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()\n",
    "log.fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d86211c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9732453214423651"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = log.predict(X_test_scaled)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "511ec316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance after applying SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     85307\n",
      "           1       0.05      0.93      0.10       136\n",
      "\n",
      "    accuracy                           0.97     85443\n",
      "   macro avg       0.53      0.95      0.54     85443\n",
      "weighted avg       1.00      0.97      0.99     85443\n",
      "\n",
      "[[83030  2277]\n",
      " [    9   127]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred = log.predict(X_test_scaled)\n",
    "print(\"Performance after applying SMOTE:\")\n",
    "print(classification_report(y_test, y_pred1))\n",
    "print(confusion_matrix(y_test, y_pred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09d4d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e3e89c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12cf3cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance after applying SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     85307\n",
      "           1       0.09      0.92      0.16       136\n",
      "\n",
      "    accuracy                           0.98     85443\n",
      "   macro avg       0.54      0.95      0.58     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      "\n",
      "[[84002  1305]\n",
      " [   11   125]]\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "svm.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_svm = svm.predict(X_test_scaled)\n",
    "print(\"Performance after applying SMOTE:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e974a27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9845979190805566"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f56ced5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.85      0.88      0.86       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.92      0.94      0.93     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "[[85286    21]\n",
      " [   17   119]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "# Initialize and train Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "print(\"Random Forest Performance:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ffd2ea60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995552590615966"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95e2f2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model (more appropriate for tabular data: use fully connected layers)\n",
    "CNN_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_resampled.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a00a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "CNN_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4573b1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0482 - val_accuracy: 0.9993 - val_loss: 0.0036\n",
      "Epoch 2/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 3/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 4/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 9.2132e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 6.8297e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 7.2150e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 1.6277e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 6.9074e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 8.9360e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 1.0932e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 1.3530e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 6.8368e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 7.7079e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 1.7962e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 3.1627e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 7.8008e-04 - val_accuracy: 1.0000 - val_loss: 2.2524e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 8.9259e-04 - val_accuracy: 1.0000 - val_loss: 4.4330e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 6.2874e-04 - val_accuracy: 1.0000 - val_loss: 9.7362e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 7.4909e-04 - val_accuracy: 0.9961 - val_loss: 0.0229\n",
      "Epoch 20/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 2.8819e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 8.9295e-04 - val_accuracy: 1.0000 - val_loss: 1.9617e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 7.6328e-04 - val_accuracy: 1.0000 - val_loss: 1.4272e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 1.2163e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 6.5658e-04 - val_accuracy: 1.0000 - val_loss: 1.1756e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 5.6275e-04 - val_accuracy: 1.0000 - val_loss: 1.2374e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 5.4693e-04 - val_accuracy: 1.0000 - val_loss: 5.5323e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 3.0440e-04 - val_accuracy: 1.0000 - val_loss: 3.5928e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9999 - val_loss: 6.4530e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 6.3835e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 4.7247e-04 - val_accuracy: 1.0000 - val_loss: 7.7270e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23680ce1390>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "CNN_model.fit(X_resampled, y_resampled, epochs=30, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bbaeb7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred = CNN_model.predict(X_test_scaled)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ef20e4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999309481\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(f'Accuracy: {accuracy:.9f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "102ba5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.78      0.79      0.78       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.89      0.89      0.89     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "[[85277    30]\n",
      " [   29   107]]\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN Performance:\")\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "print(confusion_matrix(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "94cb0d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b0a8bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SMOTE-ENN Resampling\n",
    "smote_enn = SMOTE(random_state=42)\n",
    "# Reshape the resampled data to 3D: [samples, timesteps, features]\n",
    "# For LSTM, let's use one timestep and all features in each sample\n",
    "X_resampled = np.expand_dims(X_resampled, axis=-1)  # Adds a dimension at the end for features\n",
    "X_test = np.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cec72b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model with corrected input shape\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_shape[1], input_shape[2])))  # Using the reshaped input with [samples, timesteps, features]\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(32, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1f42fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create the model with the new input shape\n",
    "lstm_model = create_lstm_model(X_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70acf78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3329d10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 16ms/step - accuracy: 0.9478 - loss: 0.1557 - val_accuracy: 0.9856 - val_loss: 0.0460\n",
      "Epoch 2/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 13ms/step - accuracy: 0.9876 - loss: 0.0351 - val_accuracy: 0.9963 - val_loss: 0.0135\n",
      "Epoch 3/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 13ms/step - accuracy: 0.9947 - loss: 0.0172 - val_accuracy: 0.9983 - val_loss: 0.0069\n",
      "Epoch 4/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 13ms/step - accuracy: 0.9969 - loss: 0.0112 - val_accuracy: 0.9962 - val_loss: 0.0117\n",
      "Epoch 5/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 13ms/step - accuracy: 0.9974 - loss: 0.0092 - val_accuracy: 0.9992 - val_loss: 0.0036\n",
      "Epoch 6/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 13ms/step - accuracy: 0.9979 - loss: 0.0077 - val_accuracy: 0.9959 - val_loss: 0.0134\n",
      "Epoch 7/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 13ms/step - accuracy: 0.9982 - loss: 0.0067 - val_accuracy: 0.9999 - val_loss: 9.7477e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 13ms/step - accuracy: 0.9986 - loss: 0.0056 - val_accuracy: 0.9998 - val_loss: 0.0014\n",
      "Epoch 9/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0044 - val_accuracy: 0.9961 - val_loss: 0.0156\n",
      "Epoch 10/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 7.3156e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 13ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 0.9998 - val_loss: 0.0023\n",
      "Epoch 12/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 13ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.9998 - val_loss: 8.5507e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.9999 - val_loss: 4.8370e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 0.9983 - val_loss: 0.0064\n",
      "Epoch 15/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 4.4859e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 13ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 3.1320e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 1.9052e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.9997 - val_loss: 0.0013\n",
      "Epoch 19/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9997 - val_loss: 0.0011\n",
      "Epoch 20/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 13ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 6.7156e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x236996078d0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the LSTM model\n",
    "lstm_model.fit(\n",
    "    X_resampled, y_resampled,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0ccdd6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "y_pred_lstm = lstm_model.predict(X_test_scaled)\n",
    "y_pred_lstm = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0aae060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9991222218320986\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Legit       1.00      1.00      1.00     85307\n",
      "       Fraud       0.68      0.86      0.76       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.84      0.93      0.88     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_lstm)\n",
    "# roc_auc = roc_auc_score(y_test, y_pred_lstm)\n",
    "report = classification_report(y_test, y_pred_lstm, target_names=['Legit', 'Fraud'])\n",
    "\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "# print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271ddde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
